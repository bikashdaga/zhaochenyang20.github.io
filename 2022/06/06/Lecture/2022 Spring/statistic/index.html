<!DOCTYPE html><html lang="en-US" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Statistics | 求道之人，不问寒暑</title><meta name="keywords" content="2022春季,数学"><meta name="author" content="Eren Zhao"><meta name="copyright" content="Eren Zhao"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="梁老师教的蛮好，你把他 PF 了干嘛？">
<meta property="og:type" content="article">
<meta property="og:title" content="Statistics">
<meta property="og:url" content="http://example.com/2022/06/06/Lecture/2022%20Spring/statistic/index.html">
<meta property="og:site_name" content="求道之人，不问寒暑">
<meta property="og:description" content="梁老师教的蛮好，你把他 PF 了干嘛？">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://pic.imgdb.cn/item/62270e7a5baa1a80ab37912d.jpg">
<meta property="article:published_time" content="2022-06-06T06:31:12.104Z">
<meta property="article:modified_time" content="2022-06-06T23:44:53.511Z">
<meta property="article:author" content="Eren Zhao">
<meta property="article:tag" content="2022春季">
<meta property="article:tag" content="数学">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pic.imgdb.cn/item/62270e7a5baa1a80ab37912d.jpg"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="canonical" href="http://example.com/2022/06/06/Lecture/2022%20Spring/statistic/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Statistics',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-06-07 07:44:53'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.0.0"><style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}</style></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpeg" onerror="onerror=null;src='/img/friend.jpg'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">175</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">53</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">12</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://pic.imgdb.cn/item/62270e7a5baa1a80ab37912d.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">求道之人，不问寒暑</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Statistics</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2022-06-06T06:31:12.104Z" title="Created 2022-06-06 14:31:12">2022-06-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2022-06-06T23:44:53.511Z" title="Updated 2022-06-07 07:44:53">2022-06-07</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AF%BE%E7%A8%8B/">课程</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word count:</span><span class="word-count">3.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading time:</span><span>17min</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Statistics"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="readme">readme</h1>
<ul>
<li>梁衡老师的概统讲的很好，<del>少数我想线下听的课</del>，可惜也没好好听，而且记了 PF，就当复习个快乐，学习没那么 targeted</li>
<li>我总结下每一章比较有意思的地方，这一部分是统计</li>
</ul>
<h1 id="统计学基本概念">统计学基本概念</h1>
<ul>
<li>样本均值</li>
</ul>
<blockquote>
<p>设 <span class="math inline">\(x_{1}, x_{2}, \cdots, x_{n}\)</span> 是来自某个总体的样本, <span class="math inline">\(\bar{x}\)</span> 为样本均值,</p>
<ol type="1">
<li>若总体分布为 <span class="math inline">\(N\left(\mu, \sigma^{2}\right)\)</span>, 则 <span class="math inline">\(\bar{x} \sim N\left(\mu, \frac{\sigma^{2}}{n}\right)\)</span>;</li>
<li>若总体分布不是正态分布或根本末知, <span class="math inline">\(E(X)=\mu, \operatorname{Var}(X)=\sigma^{2}\)</span>, 则 <span class="math inline">\(n\)</span> 较大时, <span class="math inline">\(\bar{x}\)</span> 的渐近分布为 <span class="math inline">\(N\left(\mu, \frac{\sigma^{2}}{n}\right)\)</span>, 常记为 <span class="math inline">\(\bar{x} \dot{\sim} N\left(\mu, \frac{\sigma^{2}}{n}\right)\)</span> (中心极限定理）</li>
</ol>
</blockquote>
<ul>
<li>样本方差</li>
</ul>
<blockquote>
<p>样木本方差 <span class="math inline">\(s^{2}=\frac{1}{n-1} \sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{2}\)</span></p>
<p>设总体 <span class="math inline">\(X\)</span> 具有二阶矩, 即 <span class="math inline">\(E(X)=\mu, \operatorname{Var}(X)=\sigma^{2}&lt;+\infty\)</span>, <span class="math inline">\(x_{1}, x_{2}, \cdots, x_{n}\)</span> 为从该总体得到的样本, <span class="math inline">\(\bar{x}\)</span> 和 <span class="math inline">\(s^{2}\)</span> 分别是样本均值和样本方差, 则 <span class="math inline">\(E(\bar{x})=\mu, \operatorname{Var}(\bar{x})=\frac{\sigma^{2}}{n}, E\left(s^{2}\right)=\sigma^{2}\)</span> （无偏估计）</p>
<p>注意，<span class="math inline">\(s^2\)</span> 是 <span class="math inline">\(\sigma^2\)</span> 的无偏估计，但是并不意味着 <span class="math inline">\(s\)</span> 是 <span class="math inline">\(\sigma\)</span> 的无偏估计。</p>
<p><span class="math inline">\(X_{1}, X_{2}, \cdots, X_{n}\)</span> 是来自均匀总体 <span class="math inline">\(X \sim U(-a, a)\)</span> 的样本, 用矩估计 法 估计参数 <span class="math inline">\(a\)</span>。<span class="math inline">\(\operatorname{Var}(X)=\frac{a^{2}}{3}\)</span>, 令 <span class="math inline">\(\frac{a^{2}}{3}=s^{2} \Rightarrow \hat{a}=\sqrt{3} s\)</span>，但不是无偏估计。</p>
<p>样本 <span class="math inline">\(k\)</span> 阶原点矩 <span class="math inline">\(a_{k}=\frac{1}{n} \sum_{i=1}^{n} x_{i}^{k}\)</span>, 样本 <span class="math inline">\(k\)</span> 阶中心矩 <span class="math inline">\(b_{k}=\frac{1}{n} \sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{k}\)</span></p>
</blockquote>
<ul>
<li>次序统计量</li>
</ul>
<blockquote>
<p>对于次序统计量，利用习题课 1 上的 trick 即可</p>
</blockquote>
<ul>
<li>三大分布</li>
</ul>
<blockquote>
<ol type="1">
<li><span class="math inline">\(X_{1}, X_{2}, \cdots, X_{n}\)</span> 独立同分布, 服从 <span class="math inline">\(N(0,1)\)</span> 则 <span class="math inline">\(Y=X_{1}{ }^{2}+\cdots+X_{n}{ }^{2} \sim \chi_{n}{ }^{2}\)</span> 或 <span class="math inline">\(\chi^{2}(n)\)</span>, 称为自由度为 <span class="math inline">\(n\)</span> 的 <span class="math inline">\(\chi^{2}\)</span> 分布 —— <span class="math inline">\(n\)</span> 个独立同分布的标准正态分布之和为 <span class="math inline">\(n\)</span> 自由度的卡方分布</li>
<li><span class="math inline">\(t\)</span> 分布 <span class="math inline">\(X_{1} \sim N(0,1), X_{2} \sim \chi_{n}^{2}, X_{1}, X_{2}\)</span> 相互独立 <span class="math inline">\(t=\frac{X_{1}}{\sqrt{X_{2} / n}} \sim t(n)\)</span>, 称为自由度为 <span class="math inline">\(n\)</span> 的 <span class="math inline">\(t\)</span> 分布 —— 标准正态分布除以独立的 <span class="math inline">\(n\)</span> 自由度卡方分布除 <span class="math inline">\(n\)</span> 开根为 <span class="math inline">\(n\)</span> 自由度的 <span class="math inline">\(t\)</span> 分布</li>
<li><span class="math inline">\(F\)</span> 分布 <span class="math inline">\(X_{1}, X_{2}\)</span> 相互独立, <span class="math inline">\(X_{1} \sim \chi_{m}{ }^{2}, X_{2} \sim \chi_{n}{ }^{2},F=\frac{X_{1} / m}{X_{2} / n} \sim F(m, n)\)</span> 称为自由度为 <span class="math inline">\(m\)</span> 与 <span class="math inline">\(n\)</span> 的 <span class="math inline">\(F\)</span> 分布</li>
</ol>
</blockquote>
<h1 id="参数点估计的方法与评价">参数点估计的方法与评价</h1>
<ul>
<li>矩估计</li>
</ul>
<blockquote>
<p>尽量用低阶矩来估计参数</p>
</blockquote>
<ul>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/26614750">极大似然估计</a></li>
</ul>
<blockquote>
<p>对于二元函数 <span class="math inline">\(p(x ,\theta)\)</span> 输入有两个：<span class="math inline">\(\mathrm{x}\)</span> 表示某一个具体的数据，<span class="math inline">\(\theta\)</span> 表示模型的参数</p>
<p>如果 <span class="math inline">\(\theta\)</span> 是已知确定的，<span class="math inline">\(x\)</span> 是变量, 即为概率函数(probability function)，它描述对于不同样本点 <span class="math inline">\(x\)</span>, 其出现概率是多少</p>
<p>如果 <span class="math inline">\(x\)</span> 是已知确定的，<span class="math inline">\(\theta\)</span> 是变量，这个函数叫做似然函数(likelihood function)，它描述对于不同的模型参数，出现 <span class="math inline">\(x\)</span> 这个样本点的概率是多少</p>
<p><strong>我们想办法让观察样本出现的概率最大</strong>，就是极大似然估计</p>
</blockquote>
<ul>
<li>对数似然函数</li>
</ul>
<blockquote>
<p><span class="math inline">\(\ln (L(\theta))\)</span>，由于 <span class="math inline">\(\ln x\)</span> 是 <span class="math inline">\(x\)</span> 的单调函数，使得 <span class="math inline">\(\ln (L(\theta))\)</span> 与 <span class="math inline">\(L(\theta)\)</span> 达 到最大的 <span class="math inline">\(\theta\)</span> 相同，常利用对数似然函数求解极大似然估计。</p>
</blockquote>
<ul>
<li>泊松分布与全损指数分布的极大似然估计</li>
</ul>
<blockquote>
<p><span class="math inline">\(\hat{\lambda_{Poisson}}=\overline{\boldsymbol{x}}\)</span>，<span class="math inline">\(\hat{\lambda_{Exponential}}=\frac{1}{\bar{x}}\)</span></p>
</blockquote>
<ul>
<li>有损指数分布的极大似然估计</li>
</ul>
<blockquote>
<p>设寿命小于 <span class="math inline">\(T\)</span> 的 <span class="math inline">\(r\)</span> 个观测值为 <span class="math inline">\(x_{1}, x_{2}, \cdots, x_{r}\)</span>, 对应的 <span class="math inline">\(r\)</span> 个 <span class="math inline">\(y_{k}\)</span> 的值</p>
<p>剩下的 <span class="math inline">\(n-r\)</span> 个 <span class="math inline">\(y_{k}\)</span> 的取值均为 <span class="math inline">\(T\)</span>, 每一个发生概率为 <span class="math inline">\(P(X \geq T)=e^{-\lambda T}\)</span></p>
<p>似然函数 <span class="math inline">\(L\left(\lambda ; y_{1}, y_{2}, \cdots, y_{n}\right)=\lambda^{r} e^{-\lambda\left(x_{1}+x_{2}+\cdots+x_{r}\right)} \cdot e^{-\lambda(n-r) T}\)</span> <span class="math inline">\(\ln L(\lambda)=r \ln \lambda-\lambda\left(x_{1}+x_{2}+\cdots+x_{r}\right)-\lambda(n-r) T\)</span></p>
<p><span class="math inline">\(\begin{array}{l} \frac{d \ln L(\lambda)}{d \lambda}=\frac{r}{\lambda}-\left(x_{1}+x_{2}+\cdots+x_{r}+(n-r) T\right)=0 \\ \Rightarrow \hat{\lambda}=r /\left[x_{1}+\cdots+x_{r}+(n-r) T\right] \end{array}\)</span></p>
</blockquote>
<ul>
<li>均匀分布的极大似然估计</li>
</ul>
<blockquote>
<p>参数 <span class="math inline">\(a, b\)</span> 的极大似然估计 <span class="math inline">\(\hat{a}=\min \left(\boldsymbol{X}_{1}, \boldsymbol{X}_{2} \cdots, \boldsymbol{X}_{n}\right), \hat{b}=\max \left(\boldsymbol{X}_{1}, \boldsymbol{X}_{2} \cdots, \boldsymbol{X}_{n}\right)\)</span></p>
<blockquote>
<p><strong>极大似然估计</strong>得到的不一定是无偏估计</p>
</blockquote>
</blockquote>
<ul>
<li>柯西分布的极大似然估计</li>
</ul>
<blockquote>
<p>Cauchy 分布随机变量的期望不存在, 因此不能用矩估计法对参数 <span class="math inline">\(\theta\)</span> 进行估计</p>
<p>设 <span class="math inline">\(x_{1}, x_{2}, \cdots, x_{n}\)</span> 为来自该总体的样本观测值</p>
<p>似然函数 <span class="math inline">\(L(\theta)=\prod_{k=1}^{n} f\left(x_{k} ; \theta\right)=\prod_{k=1}^{n} \frac{1}{\pi\left[1+\left(x_{k}-\theta\right)^{2}\right]}\)</span></p>
<p>对数似然函数 <span class="math inline">\(\ln L(\theta)=\sum_{k=1}^{n}-\left(\ln \pi+\ln \left(1+\left(x_{k}-\theta\right)^{2}\right)\right)\)</span></p>
<p>将上式对 <span class="math inline">\(\theta\)</span> 求导，并令其等于 0</p>
<p><span class="math inline">\(\frac{d \ln L(\theta)}{d \theta}=-\sum_{k=1}^{n} \frac{x_{k}-\theta}{1+\left(x_{k}-\theta\right)^{2}}=0\)</span></p>
<p>方程无法的到解析解，需要用一定的计算方法近似求解</p>
</blockquote>
<ul>
<li>相合估计</li>
</ul>
<blockquote>
<p>定理: 设 <span class="math inline">\(\hat{\theta}_{n}=\hat{\theta}_{n}\left(x_{1}, x_{2}, \cdots, x_{n}\right)\)</span> 是 <span class="math inline">\(\theta\)</span> 的一个估计量, 若 <span class="math inline">\(\lim _{n \rightarrow \infty} E\left(\hat{\theta}_{n}\right)=\theta \quad \lim _{n \rightarrow \infty} \operatorname{Var}\left(\hat{\theta}_{n}\right)=0\)</span>，则 <span class="math inline">\(\hat{\theta}_{n}\)</span> 是参数 <span class="math inline">\(\theta\)</span> 的相合估计。</p>
</blockquote>
<ul>
<li>无偏性与有效性</li>
</ul>
<blockquote>
<p>无偏性，保证没有系统偏差</p>
<p>设 <span class="math inline">\(\theta \in \Theta\)</span> 为末知参数, <span class="math inline">\(\hat{\theta}=\hat{\theta}\left(x_{1}, x_{2}, \cdots, x_{n}\right)\)</span> 是 <span class="math inline">\(\theta\)</span> 的一个估计量，若对任意 <span class="math inline">\(\theta \in \Theta\)</span> 有 <span class="math inline">\(E(\hat{\theta})=\theta\)</span>，则称 <span class="math inline">\(\hat{\theta}\)</span> 是参数 <span class="math inline">\(\theta\)</span> 的无偏估计。</p>
<p>有效性，希望估计围绕参数波动的幅度越小越好。</p>
<p>设 <span class="math inline">\(\hat{\theta}_{1}, \hat{\theta}_{2}\)</span> 是参数 <span class="math inline">\(\theta\)</span> 的无偏估计，如果对任意 <span class="math inline">\(\theta \in \Theta\)</span> 有 <span class="math inline">\(\operatorname{Var}\left(\hat{\theta}_{1}\right) \leq \operatorname{Var}\left(\hat{\theta}_{2}\right)\)</span>，且至少有一个 <span class="math inline">\(\theta \in \Theta\)</span> 使得上述不等号严格成立，则称 <span class="math inline">\(\hat{\theta}_{1}\)</span> 比 <span class="math inline">\(\hat{\theta}_{2}\)</span> 有效。</p>
<p>简单的应用: 样本数量的增加会改善估计。</p>
</blockquote>
<ul>
<li><strong>极大似然估计</strong>得到的不一定是无偏估计</li>
</ul>
<blockquote>
<p>例 <span class="math inline">\(1 X_{1}, X_{2}, \cdots, X_{n}\)</span> 是来自均匀总体 <span class="math inline">\(U(0, \theta)\)</span> 的样本，参数 <span class="math inline">\(\theta\)</span> 的极大似然估计量 <span class="math inline">\(\tilde{\theta}=\max _{1 \leq k \leq n} X_{k}\)</span>, 考查无偏性。</p>
<p>计算 <span class="math inline">\(\tilde{\theta}=\max _{1 \leq k \leq n} X_{k}\)</span> 的分布函数，当 <span class="math inline">\(0 \leq y \leq \theta\)</span> 时, 由样本的独立同分布性质，可知其分布函数（CDF）为 <span class="math display">\[
F_{\dot{\theta}}(y)=P(\tilde{\theta} \leq y)=P\left(\max _{1 \leq k \leq n} X_{k} \leq y\right)=\prod_{k=1}^{n} P\left(X_{k} \leq y\right)=\left(\frac{y}{\theta}\right)^{n}
\]</span> <span class="math inline">\(\tilde{\theta}=\max _{1 \leq k \leq n} X_{k}\)</span> 的分布函数 <span class="math inline">\(F_{\tilde{\theta}}(y)=\left\{\begin{array}{c}0, y&lt;0 \\ \left(\frac{y}{\theta}\right)^{n}, 0 \leq y \leq \theta, \\ 1, y&gt;\theta\end{array}\right.\)</span> 于是 <span class="math inline">\(\tilde{\theta}\)</span> 的概率密度（PDF）为 <span class="math inline">\(f_{\tilde{\theta}}(y)=\left\{\begin{array}{c}\frac{n}{\theta^{n}} y^{n-1}, y \in[0, \theta] \\ 0, \text { 其它 }\end{array} \quad\right.\)</span> 因此, 我们有 <span class="math display">\[
\begin{aligned}
E(\tilde{\theta}) &amp;=\int_{-\infty}^{+\infty} y f_{\tilde{\theta}}(y) d y=\int_{0}^{\theta} y \frac{n}{\theta^{n}} y^{n-1} d y \\
&amp;=\frac{n}{\theta^{n}} \int_{0}^{\theta} y^{n} d y=\left.\frac{n}{\theta^{n}} \cdot \frac{y^{n+1}}{n+1}\right|_{0} ^{\theta}=\frac{n}{n+1} \theta
\end{aligned}
\]</span> <span class="math inline">\(E(\tilde{\theta})=E\left(\max _{1 \leq k \leq n} X_{k}\right)=\frac{n}{n+1} \theta\)</span>，统计量 <span class="math inline">\(\max _{1 \leq k \leq n} X_{k}\)</span> 不是参数 <span class="math inline">\(\theta\)</span> 的无偏估计，<span class="math inline">\(\frac{n+1}{n} \max _{1 \leq k \leq n} X_{k}\)</span> 则为无偏估计，称为无偏校正。</p>
</blockquote>
<ul>
<li>正态分布的极大似然估计</li>
</ul>
<blockquote>
<p>所以参数 <span class="math inline">\(\mu\)</span> 和 <span class="math inline">\(\sigma^{2}\)</span> 的极大似然估计量为 <span class="math inline">\(\hat{\mu}=\bar{X}, \hat{\sigma}^{2}=\frac{1}{n} \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}\)</span></p>
<p>注意，不是估计的 <span class="math inline">\(\sigma\)</span>，而是 <span class="math inline">\(\sigma^2\)</span></p>
</blockquote>
<ul>
<li>均方误差</li>
</ul>
<blockquote>
<p><span class="math display">\[
\begin{aligned}
\operatorname{MSE}(\hat{\theta})=E(\hat{\theta}-\theta)^{2} &amp;=E[(\hat{\theta}-E(\hat{\theta}))+(E(\hat{\theta})-\theta)]^{2} \\
&amp;=\operatorname{Var}(\hat{\theta})+(\boldsymbol{E}(\hat{\theta})-\theta)^{2}
\end{aligned}
\]</span> 若 <span class="math inline">\(\hat{\theta}\)</span> 是参数 <span class="math inline">\(\theta\)</span> 的无偏估计, 则 <span class="math inline">\(\operatorname{MSE}(\hat{\theta})=\operatorname{Var}(\hat{\theta})\)</span></p>
<p>注: 很多时候, 无偏估计的均方误差会小于有偏估计的均方误差, 但 二者之间并没有严格的对应关系，例如书上324页（第三版286-287页)</p>
<p>例 6.4.1 即给出一个有偏估计均方误差小于无偏估计均方误差的实例。</p>
</blockquote>
<h1 id="参数区间估计">参数区间估计</h1>
<ul>
<li>置信系数</li>
</ul>
<blockquote>
<p>抽取 n 个样本得到一个区间估计, 将这样的估计重复足够多次, 至少 <span class="math inline">\(1-\alpha\)</span> 比例的估计区间包含真实的 <span class="math inline">\(\mu\)</span> 值。这里置信系数是 <span class="math inline">\(0.9544\)</span>, 即大约 <span class="math inline">\(95.44 \%\)</span> 估计区间包含真实的 <span class="math inline">\(\mu\)</span> 值。</p>
<p>或者说，这种抽样方法得到的这些区间至少有 <span class="math inline">\(1-\alpha\)</span> 的概率包含真实的 <span class="math inline">\(\mu\)</span> 值。</p>
<p>末知参数本身是确定的值, 不带有随机性。随机性是由区间引入的。</p>
</blockquote>
<ul>
<li>下侧 <span class="math inline">\(\alpha\)</span> 分位数</li>
</ul>
<blockquote>
<p><span class="math inline">\(\Phi(d)=1-\frac{\alpha}{2}, \quad F(c)=\frac{\alpha}{2} \quad \Rightarrow \quad d=\Phi^{-1}\left(1-\frac{\alpha}{2}\right), \quad c=\Phi^{-1}\left(\frac{\alpha}{2}\right)\)</span></p>
<p>标准正态分布的 <span class="math inline">\(1-\frac{\alpha}{2}\)</span> 分位数和 <span class="math inline">\(\frac{\alpha}{2}\)</span> 分位数，<span class="math inline">\(d=u_{1-\frac{\alpha}{2}}, \quad c=u_{\frac{\alpha}{2}}=-u_{1-\frac{\alpha}{2}}\)</span></p>
<p>最主要的还是理解分位数的反函数定义，小于 <span class="math inline">\(\alpha\)</span> 分位点的概率是 <span class="math inline">\(\alpha\)</span></p>
</blockquote>
<blockquote>
<p>标准正态分布的 <span class="math inline">\(\alpha\)</span> 分位点记为 <span class="math inline">\(u_{\alpha}\)</span></p>
<p><span class="math inline">\(n\)</span> 个自由度的 <span class="math inline">\(\chi^{2}\)</span> 分布的 <span class="math inline">\(\alpha\)</span> 分位点记为 <span class="math inline">\(\chi_{\alpha}^{2}(n)\)</span></p>
<p><span class="math inline">\(n\)</span> 个自由度的 <span class="math inline">\(t\)</span> 分布的 <span class="math inline">\(\alpha\)</span> 分位点记为 <span class="math inline">\(t_{\alpha}(n)\)</span></p>
<p><span class="math inline">\((m, n)\)</span> 自由度的 <span class="math inline">\(F\)</span> 分布的 <span class="math inline">\(\alpha\)</span> 分位点记为 <span class="math inline">\(F_{\alpha}(m, n)\)</span></p>
<p><span class="math inline">\(X\)</span> 为一连续分布随机变量, 如果 <span class="math inline">\(P(X \geq a)=\alpha\)</span>, <span class="math inline">\(a\)</span> 称为上侧 <span class="math inline">\(\alpha\)</span> 分位数</p>
</blockquote>
<ul>
<li>统计抽样定理</li>
</ul>
<blockquote>
<p>设 <span class="math inline">\(x_{1}, x_{2}, \cdots, x_{n}\)</span> 是来自正态总体 <span class="math inline">\(N\left(\mu, \sigma^{2}\right)\)</span> 的样本, 其样本均值和 样本方差分别为: <span class="math inline">\(\bar{x}=\frac{x_{1}+x_{2}+\cdots+x_{n}}{n}\)</span> 和 <span class="math inline">\(s^{2}=\frac{1}{n-1} \sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{2}\)</span>, 则有</p>
<ol type="1">
<li><span class="math inline">\(\bar{x}\)</span> 与 <span class="math inline">\(s^{2}\)</span> 相互独立</li>
<li><span class="math inline">\(\bar{x} \sim N\left(\mu, \frac{\sigma^{2}}{n}\right)\)</span></li>
<li><span class="math inline">\(\frac{(n-1) \cdot s^{2}}{\sigma^{2}} \sim \chi^{2}(n-1)\)</span></li>
</ol>
</blockquote>
<ul>
<li>方差已知区间估计</li>
</ul>
<blockquote>
<p>总体 <span class="math inline">\(N\left(\mu, \sigma^{2}\right), \sigma^{2}\)</span> 已知, <span class="math inline">\(\mu\)</span> 末知, <span class="math inline">\(x_{1}, x_{2}, \cdots, x_{n}\)</span> 是简单随机样本, 求 <span class="math inline">\(\mu\)</span> 的1- <span class="math inline">\(\alpha\)</span> 置信区间 。<span class="math inline">\(\frac{\bar{x}-\mu}{\sqrt{\frac{\sigma^{2}}{n}}}\)</span> 可作为枢轴量, <span class="math inline">\(Z=\frac{\bar{x}-\mu}{\sqrt{\frac{\sigma^{2}}{n}}}=\frac{\sqrt{n}(\bar{x}-\mu)}{\sigma} \sim N(0,1)\)</span></p>
</blockquote>
<ul>
<li>方差未知区间估计</li>
</ul>
<blockquote>
<p>总体 <span class="math inline">\(X \sim N\left(\mu, \sigma^{2}\right), \sigma^{2}\)</span> 末知。</p>
<ol type="1">
<li>求参数 <span class="math inline">\(\mu\)</span> 的 <span class="math inline">\(1-\alpha\)</span> 置信区间</li>
</ol>
<p><span class="math inline">\(\bar{x} \sim N\left(\mu, \frac{\sigma^{2}}{n}\right), \quad \frac{\bar{x}-\mu}{\sigma / \sqrt{n}} \sim N(0,1)\)</span></p>
<p><span class="math inline">\(\bar{x}\)</span> 与 <span class="math inline">\(s^{2}\)</span> 相互独立, 且 <span class="math inline">\(\frac{(n-1) \cdot s^{2}}{\sigma^{2}} \sim \chi^{2}(n-1)\)</span></p>
<p><span class="math inline">\(\frac{\frac{\bar{x}-\mu}{\sigma / \sqrt{n}}}{\sqrt{\frac{(n-1) \cdot s^{2}}{\sigma^{2}}}}\)</span> 可以将 <span class="math inline">\(\sigma\)</span> 的影响消去。</p>
<p><span class="math inline">\(\frac{\frac{\bar{x}-\mu}{\sigma / \sqrt{n}}}{\frac{\sigma^{2}}{\sigma / s^{2}} /(n-1)}=\frac{\bar{x}-\mu}{s / \sqrt{n}} \sim t(n-1)\)</span></p>
<p><span class="math inline">\(-t_{1-\frac{\alpha}{2}}(n-1) \leq \frac{\sqrt{n}(\bar{x}-\mu)}{s} \leq t_{1-\frac{\alpha}{2}}(n-1)\)</span></p>
<p><span class="math inline">\(\bar{x}-\frac{s}{\sqrt{n}} t_{1-\frac{\alpha}{2}}(n-1) \leq \mu \leq \bar{x}+\frac{s}{\sqrt{n}} t_{1-\frac{\alpha}{2}}(n-1)\)</span></p>
<ol start="2" type="1">
<li>求 <span class="math inline">\(\sigma^{2}\)</span> 的 <span class="math inline">\(1-\alpha\)</span> 置信区间</li>
</ol>
<p><span class="math inline">\(\frac{(n-1) s^{2}}{\sigma^{2}} \sim \chi^{2}(n-1)\)</span> 可作为枢轴量 <span class="math inline">\(\left(\chi_{\frac{\alpha}{2}}^{2} \leq \frac{(n-1) s^{2}}{\sigma^{2}} \leq \chi_{1-\frac{\alpha}{2}}^{2}\right)=1-\alpha\)</span> <span class="math inline">\(P\left(\frac{(n-1) s^{2}}{\chi_{1-\frac{\alpha}{2}}^{2}} \leq \sigma^{2} \leq \frac{(n-1) s^{2}}{\chi_{\frac{\alpha}{2}}^{2}}\right)=1-\alpha \Rightarrow \sigma^{2} \in\left[\frac{(n-1) s^{2}}{\chi_{1-\frac{\alpha}{2}}^{2}}, \frac{(n-1) s^{2}}{\chi_{\frac{\alpha}{2}}^{2}}\right]\)</span></p>
<p><strong>去除未知参数的影响</strong></p>
</blockquote>
<ul>
<li>Behrens-Fisher 问题</li>
</ul>
<blockquote>
<p><span class="math inline">\(x_{1}, \cdots, x_{m}\)</span> 来自正态总体 <span class="math inline">\(N\left(\mu_{1}, \sigma_{1}{ }^{2}\right), y_{1}, \cdots, y_{n}\)</span> 来自正态总体 <span class="math inline">\(N\left(\mu_{2}, \sigma_{2}{ }^{2}\right), \mu_{1} 、 \mu_{2}\)</span> 末知， <span class="math inline">\(\sigma_{1}{ }^{2}=\sigma_{2}{ }^{2}=\sigma^2\)</span> 末知，求 <span class="math inline">\(\mu_{2}-\mu_{1}\)</span> 的 <span class="math inline">\(1-\alpha\)</span> 置信区间。</p>
<p><span class="math inline">\(\bar{x} \sim N\left(\mu_{1}, \frac{\sigma^{2}}{m}\right), \bar{y} \sim N\left(\mu_{2}, \frac{\sigma^{2}}{n}\right), \quad \bar{x}-\bar{y} \sim N\left(\mu_{1}-\mu_{2}, \frac{\sigma^{2}}{m}+\frac{\sigma^{2}}{n}\right)\)</span></p>
<p><span class="math inline">\(\frac{(m-1) s_{x}^{2}}{\sigma^{2}} \sim \chi^{2}(m-1), \frac{(n-1) s_{y}^{2}}{\sigma^{2}} \sim \chi^{2}(n-1), \quad \frac{(m-1) s_{x}^{2}}{\sigma^{2}}+\frac{(n-1) s_{y}^{2}}{\sigma^{2}} \sim \chi^{2}(m+n-2)\)</span></p>
<p><span class="math inline">\(\frac{\frac{(\bar{x}-\bar{y})-\left(\mu_{1}-\mu_{2}\right)}{\sigma \sqrt{\frac{1}{m}+\frac{1}{n}}}}{\sqrt{\frac{(m-1) s_{x}^{2}+(n-1) s_{y}^{2}}{\sigma^{2}} /(m+n-2)}}=\frac{\sqrt{m+n-2}}{\sqrt{\frac{1}{m}+\frac{1}{n}}} \cdot \frac{(\bar{x}-\bar{y})-\left(\mu_{1}-\mu_{2}\right)}{\sqrt{(m-1) s_{x}^{2}+(n-1) s_{y}^{2}}} \sim t(m+n-2)\)</span></p>
</blockquote>
<ul>
<li>正态方差之商的区间估计</li>
</ul>
<blockquote>
<p>例 <span class="math inline">\(x_{1}, \cdots, x_{m}\)</span> 来自正态总体 <span class="math inline">\(N\left(\mu_{1}, \sigma_{1}^{2}\right), y_{1}, \cdots, y_{n}\)</span> 来自正态总体 <span class="math inline">\(N\left(\mu_{2}, \sigma_{2}{ }^{2}\right)\)</span>, <span class="math inline">\(\mu_{1} 、 \mu_{2}\)</span> 末知， <span class="math inline">\(\sigma_{1}{ }^{2} 、 \sigma_{2}{ }^{2}\)</span> 末知, 求 <span class="math inline">\(\sigma_{1}{ }^{2} / \sigma_{2}{ }^{2}\)</span> 的区间估计。</p>
<p><span class="math inline">\(\begin{array}{l} \frac{(m-1) s_{1}{ }^{2}}{\sigma_{1}{ }^{2}} \sim \chi^{2}(m-1), \quad \frac{(n-1) s_{2}{ }^{2}}{\sigma_{2}{ }^{2}} \sim \chi^{2}(n-1) \\ \Rightarrow \quad F=\frac{s_{1}{ }^{2} / \sigma_{1}{ }^{2}}{s_{2}{ }^{2} / \sigma_{2}{ }^{2}} \sim F(m-1, n-1) \end{array}\)</span></p>
</blockquote>
<ul>
<li>指数分布的区间分布</li>
</ul>
<blockquote>
<p><span class="math inline">\(x_{1}, \cdots, x_{n}\)</span> 来自指数总体 <span class="math inline">\(\operatorname{Exp}(\lambda)\)</span>, 求参数 <span class="math inline">\(\lambda\)</span> 的区间估计</p>
<p>可以证明 <span class="math inline">\(X=2 \lambda\left(x_{1}+\cdots+x_{n}\right) \sim \chi^{2}(2 n) \Rightarrow 2 n \lambda \bar{x} \sim \chi^{2}(2 n)\)</span></p>
<p><span class="math inline">\(P\left(\chi_{\frac{\alpha}{2}}^{2}(2 n) \leq 2 n \lambda \bar{x} \leq \chi_{1-\frac{\alpha}{2}}^{2}(2 n)\right)=1-\alpha\)</span> <span class="math inline">\(\Rightarrow \chi_{\frac{\alpha}{2}}^{2}(2 n) \leq 2 n \lambda \bar{x} \leq \chi_{1-\frac{\alpha}{2}}^{2}(2 n)\)</span> <span class="math inline">\(\Rightarrow \lambda \in\left[\chi_{\frac{\alpha}{2}}^{2}(2 n) / 2 n \bar{x}, \chi_{1-\frac{\alpha}{2}}^{2}(2 n) / 2 n \bar{x}\right]\)</span></p>
</blockquote>
<ul>
<li>均匀分布的区间估计</li>
</ul>
<blockquote>
<p><span class="math inline">\(F_{x_{(j)}}(x, \theta)=\left(\frac{x}{\theta}\right)^{n}, \quad Y=\frac{x_{(n)}}{\theta}, \quad F_{Y}(y)=P(Y&lt;y)=P\left(\frac{x_{(n)}}{\theta}&lt;y\right)=y^{n}\)</span></p>
<p><span class="math inline">\(\frac{x_{(n)}}{\theta}\)</span> 可作为枢轴量</p>
<p><span class="math inline">\(P\left(c \leq \frac{x_{(n)}}{\theta} \leq d\right)=d^{n}-c^{n}=1-\alpha \Rightarrow \frac{x_{(n)}}{d} \leq \theta \leq \frac{x_{(n)}}{c}\)</span></p>
<p>可取 <span class="math inline">\(d=1, c=\sqrt[n]{\alpha}, \quad \theta \in\left[x_{(n)}, \frac{x_{(n)}}{\sqrt[n]{\alpha}}\right]\)</span></p>
</blockquote>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Eren Zhao</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://example.com/2022/06/06/Lecture/2022%20Spring/statistic/">http://example.com/2022/06/06/Lecture/2022%20Spring/statistic/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/2022%E6%98%A5%E5%AD%A3/">2022春季</a><a class="post-meta__tags" href="/tags/%E6%95%B0%E5%AD%A6/">数学</a></div><div class="post_share"><div class="social-share" data-image="https://pic.imgdb.cn/item/62270e7a5baa1a80ab37912d.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/06/06/Lecture/2022%20Spring/deep_learning/"><img class="prev-cover" src="https://pic.imgdb.cn/item/61f2b2892ab3f51d91051bb8.jpg" onerror="onerror=null;src='https://wkphoto.cdn.bcebos.com/1f178a82b9014a9058a735deb9773912b31bee3c.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">Segement Me If U Can</div></div></a></div><div class="next-post pull-right"><a href="/2022/06/04/%E7%A3%95%E7%9B%90/Gau%20GAN/"><img class="next-cover" src="https://pic.imgdb.cn/item/61f0fc662ab3f51d9172fef0.jpg" onerror="onerror=null;src='https://wkphoto.cdn.bcebos.com/1f178a82b9014a9058a735deb9773912b31bee3c.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">Understanding Gau GAN</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2022/02/23/Lecture/2022%20Spring/probability/" title="Probability"><img class="cover" src="https://pic.imgdb.cn/item/61f0fc772ab3f51d9173149e.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-02-23</div><div class="title">Probability</div></div></a></div><div><a href="/2022/04/02/Lecture/2022%20Spring/distribution/" title="Distribution Is All U Need"><img class="cover" src="https://pic.imgdb.cn/item/623475f75baa1a80ab3b54f1.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-04-02</div><div class="title">Distribution Is All U Need</div></div></a></div><div><a href="/2022/03/22/Lecture/2022%20Spring/Computer_graphics/" title="Computer Graphics"><img class="cover" src="https://pic.imgdb.cn/item/61eccb6b2ab3f51d91d62fc2.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-22</div><div class="title">Computer Graphics</div></div></a></div><div><a href="/2022/05/25/%E9%9A%8F%E7%AC%94/%E6%B8%85%E5%8D%8E%E5%9B%AD%E6%97%A5%E8%AE%B0/%E6%B8%85%E5%8D%8E%E5%9B%AD%E6%97%A5%E8%AE%B0--%E7%AC%AC%E4%BA%94%E9%83%A8/" title="清华园日记——第五部"><img class="cover" src="https://zhaochenyang20.github.io/pic/embed/5_31_1.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-25</div><div class="title">清华园日记——第五部</div></div></a></div><div><a href="/2022/05/17/Lecture/2022%20Spring/binaryDivdence/" title="深度学习基础"><img class="cover" src="https://pic.imgdb.cn/item/6234754d5baa1a80ab39c4c4.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-17</div><div class="title">深度学习基础</div></div></a></div><div><a href="/2022/06/06/Lecture/2022%20Spring/deep_learning/" title="Segement Me If U Can"><img class="cover" src="https://pic.imgdb.cn/item/61f2b2892ab3f51d91051bb8.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-06-06</div><div class="title">Segement Me If U Can</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpeg" onerror="this.onerror=null;this.src='/img/friend.jpg'" alt="avatar"/></div><div class="author-info__name">Eren Zhao</div><div class="author-info__description">求道之人，不论寒暑，无问西东</div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">175</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">53</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">12</div></a></div></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/zhaochenyang20"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">La vida sola viviras</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#readme"><span class="toc-number">1.</span> <span class="toc-text">readme</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BB%9F%E8%AE%A1%E5%AD%A6%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-number">2.</span> <span class="toc-text">统计学基本概念</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E7%82%B9%E4%BC%B0%E8%AE%A1%E7%9A%84%E6%96%B9%E6%B3%95%E4%B8%8E%E8%AF%84%E4%BB%B7"><span class="toc-number">3.</span> <span class="toc-text">参数点估计的方法与评价</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E5%8C%BA%E9%97%B4%E4%BC%B0%E8%AE%A1"><span class="toc-number">4.</span> <span class="toc-text">参数区间估计</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/06/06/Lecture/2022%20Spring/deep_learning/" title="Segement Me If U Can"><img src="https://pic.imgdb.cn/item/61f2b2892ab3f51d91051bb8.jpg" onerror="this.onerror=null;this.src='https://wkphoto.cdn.bcebos.com/1f178a82b9014a9058a735deb9773912b31bee3c.jpg'" alt="Segement Me If U Can"/></a><div class="content"><a class="title" href="/2022/06/06/Lecture/2022%20Spring/deep_learning/" title="Segement Me If U Can">Segement Me If U Can</a><time datetime="2022-06-06T08:50:44.589Z" title="Created 2022-06-06 16:50:44">2022-06-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/06/06/Lecture/2022%20Spring/statistic/" title="Statistics"><img src="https://pic.imgdb.cn/item/62270e7a5baa1a80ab37912d.jpg" onerror="this.onerror=null;this.src='https://wkphoto.cdn.bcebos.com/1f178a82b9014a9058a735deb9773912b31bee3c.jpg'" alt="Statistics"/></a><div class="content"><a class="title" href="/2022/06/06/Lecture/2022%20Spring/statistic/" title="Statistics">Statistics</a><time datetime="2022-06-06T06:31:12.104Z" title="Created 2022-06-06 14:31:12">2022-06-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/06/04/%E7%A3%95%E7%9B%90/Gau%20GAN/" title="Understanding Gau GAN"><img src="https://pic.imgdb.cn/item/61f0fc662ab3f51d9172fef0.jpg" onerror="this.onerror=null;this.src='https://wkphoto.cdn.bcebos.com/1f178a82b9014a9058a735deb9773912b31bee3c.jpg'" alt="Understanding Gau GAN"/></a><div class="content"><a class="title" href="/2022/06/04/%E7%A3%95%E7%9B%90/Gau%20GAN/" title="Understanding Gau GAN">Understanding Gau GAN</a><time datetime="2022-06-03T23:58:17.445Z" title="Created 2022-06-04 07:58:17">2022-06-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/05/25/%E9%9A%8F%E7%AC%94/%E6%B8%85%E5%8D%8E%E5%9B%AD%E6%97%A5%E8%AE%B0/%E6%B8%85%E5%8D%8E%E5%9B%AD%E6%97%A5%E8%AE%B0--%E7%AC%AC%E4%BA%94%E9%83%A8/" title="清华园日记——第五部"><img src="https://zhaochenyang20.github.io/pic/embed/5_31_1.jpg" onerror="this.onerror=null;this.src='https://wkphoto.cdn.bcebos.com/1f178a82b9014a9058a735deb9773912b31bee3c.jpg'" alt="清华园日记——第五部"/></a><div class="content"><a class="title" href="/2022/05/25/%E9%9A%8F%E7%AC%94/%E6%B8%85%E5%8D%8E%E5%9B%AD%E6%97%A5%E8%AE%B0/%E6%B8%85%E5%8D%8E%E5%9B%AD%E6%97%A5%E8%AE%B0--%E7%AC%AC%E4%BA%94%E9%83%A8/" title="清华园日记——第五部">清华园日记——第五部</a><time datetime="2022-05-24T23:05:19.199Z" title="Created 2022-05-25 07:05:19">2022-05-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/05/24/Lecture/2022%20Spring/Reinforcement/" title="重力四子棋"><img src="https://pic.imgdb.cn/item/61eccb502ab3f51d91d619c6.jpg" onerror="this.onerror=null;this.src='https://wkphoto.cdn.bcebos.com/1f178a82b9014a9058a735deb9773912b31bee3c.jpg'" alt="重力四子棋"/></a><div class="content"><a class="title" href="/2022/05/24/Lecture/2022%20Spring/Reinforcement/" title="重力四子棋">重力四子棋</a><time datetime="2022-05-24T06:16:40.717Z" title="Created 2022-05-24 14:16:40">2022-05-24</time></div></div></div></div></div></div></main><footer id="footer" style="background: ＃191970"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By Eren Zhao</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Local search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading the Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/tororo.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/"});</script></body></html>
<!DOCTYPE html><html lang="en-US" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>connect 4 based on Reinforced Learning | 求道之人，不问寒暑</title><meta name="keywords" content="科研,2022春季"><meta name="author" content="Eren Zhao"><meta name="copyright" content="Eren Zhao"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="蒙特卡罗方法得名于发明者的叔叔，他经常在摩纳哥的蒙特卡洛赌场输钱...">
<meta property="og:type" content="article">
<meta property="og:title" content="connect 4 based on Reinforced Learning">
<meta property="og:url" content="http://example.com/2022/05/24/Lecture/2022%20Spring/Reinforcement/index.html">
<meta property="og:site_name" content="求道之人，不问寒暑">
<meta property="og:description" content="蒙特卡罗方法得名于发明者的叔叔，他经常在摩纳哥的蒙特卡洛赌场输钱...">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://pic.imgdb.cn/item/62270f075baa1a80ab393529.jpg">
<meta property="article:published_time" content="2022-05-24T06:16:40.717Z">
<meta property="article:modified_time" content="2022-05-27T07:58:39.979Z">
<meta property="article:author" content="Eren Zhao">
<meta property="article:tag" content="科研">
<meta property="article:tag" content="2022春季">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pic.imgdb.cn/item/62270f075baa1a80ab393529.jpg"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="canonical" href="http://example.com/2022/05/24/Lecture/2022%20Spring/Reinforcement/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'connect 4 based on Reinforced Learning',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-05-27 15:58:39'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.0.0"><style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}</style></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpeg" onerror="onerror=null;src='/img/friend.jpg'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">172</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">53</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">12</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://pic.imgdb.cn/item/62270f075baa1a80ab393529.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">求道之人，不问寒暑</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">connect 4 based on Reinforced Learning</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2022-05-24T06:16:40.717Z" title="Created 2022-05-24 14:16:40">2022-05-24</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2022-05-27T07:58:39.979Z" title="Updated 2022-05-27 15:58:39">2022-05-27</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AF%BE%E7%A8%8B/">课程</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">Word count:</span><span class="word-count">4.1k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">Reading time:</span><span>12min</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="connect 4 based on Reinforced Learning"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="重力四子棋">重力四子棋</h1>
<p><a target="_blank" rel="noopener" href="https://zhaochenyang20.github.io/">Eren Zhao</a></p>
<p>赵晨阳 计 06 2020012363</p>
<h1 id="强化学习">强化学习</h1>
<h2 id="概念">概念</h2>
<p>强化学习是机器学习中的一个领域，强调如何基于环境而行动，以取得最大化的预期利益。其灵感来源于心理学中的行为主义理论，即有机体如何在环境给予的奖励或惩罚的刺激下，逐步形成对刺激的预期，产生能获得最大利益的习惯性行为。这个方法具有普适性，因此在其他许多领域都有研究，例如博弈论、控制论、运筹学、信息论、仿真优化、多主体系统学习、群体智能、统计学以及遗传算法。在运筹学和控制理论研究的语境下，强化学习被称作“近似动态规划”（approximate dynamic programming，ADP）。在最优控制理论中也有研究这个问题，虽然大部分的研究是关于最优解的存在和特性，并非是学习或者近似方面。在经济学和博弈论中，强化学习被用来解释在有限理性的条件下如何出现平衡。</p>
<p>在机器学习问题中，环境通常被规范为<strong>马尔可夫决策过程（MDP）</strong>，许多强化学习算法在这种情况下使用动态规划技巧。 强化学习和标准的监督式学习之间的区别在于，它<strong>并不需要出现正确的输入/输出对，也不需要精确校正次优化的行为</strong>。</p>
<p>强化学习更加专注于在线规划，需要在探索（在未知的领域）和遵从（现有知识）之间找到平衡。强化学习中的“探索-遵从”的交换，在多臂老虎机（英语：multi-armed bandit）问题和有限MDP中研究得最多。</p>
<h2 id="强化学习的基本组件">强化学习的基本组件</h2>
<ul>
<li>环境/状态（标准的为静态stationary，对应的non-stationary）</li>
<li>agent（与环境交互的对象）</li>
<li>动作（action space，环境下可行的动作集合，离散/连续）</li>
<li>反馈（回报，reward，正是有了反馈，RL才能迭代，才会学习到策略链）</li>
</ul>
<h1 id="马尔可夫决策过程mdp">马尔可夫决策过程（MDP）</h1>
<h2 id="马尔可夫过程">马尔可夫过程</h2>
<p>在概率论及统计学中，马尔可夫过程（Markov process）又叫马尔可夫链(Markov Chain)，是一个具备了马尔可夫性质的随机过程，因为俄国数学家安德雷·马尔可夫得名。马尔可夫过程是不具备记忆特质的（memorylessness）。换言之，马尔可夫过程的条件概率仅仅与系统的当前状态相关，而与它的过去历史或未来状态，都是独立、不相关的。马尔可夫过程可以用一个元组表示，其中 S 是有限数量的状态集，P 是状态转移概率矩阵。</p>
<h2 id="马尔可夫奖励过程">马尔可夫奖励过程</h2>
<p>马尔可夫奖励过程（Markov Reward Process）在马尔可夫过程的基础上增加了奖励 R 和衰减系数 γ。R 是一个奖励函数。S 状态下的奖励是某一时刻 t 处在状态 s 下在下一个时刻 t+1 能获得的奖励期望（当进入某个状态会获得相应的奖励）。</p>
<h2 id="rl-与-mdp">RL 与 MDP</h2>
<p>在强化学习中，马尔可夫决策过程是对完全可观测的环境进行描述的，也就是说观测到的状态内容完整地决定了决策的需要的特征。几乎所有的强化学习问题都可以转化为 MDP。</p>
<h1 id="蒙特卡洛方法mcm">蒙特卡洛方法（MCM）</h1>
<h2 id="简介">简介</h2>
<p>蒙特卡罗方法（Monte Carlo Method），也称统计模拟方法，是1940年代中期由于科学技术的发展和电子计算机的发明，而提出的一种以概率统计理论为指导的数值计算方法。是指使用随机数（或更常见的伪随机数）来解决很多计算问题的方法。</p>
<p>20世纪40年代，在冯·诺伊曼，斯塔尼斯拉夫·乌拉姆和尼古拉斯·梅特罗波利斯在洛斯阿拉莫斯国家实验室为核武器计划工作时，发明了蒙特卡罗方法。因为乌拉姆的叔叔经常在摩纳哥的蒙特卡洛赌场输钱得名，而蒙特卡罗方法正是以概率为基础的方法。</p>
<p>通常蒙特卡罗方法可以粗略地分成两类：一类是所求解的问题本身具有内在的随机性，借助计算机的运算能力可以直接模拟这种随机的过程。例如在核物理研究中，分析中子在反应堆中的传输过程。中子与原子核作用受到量子力学规律的制约，人们只能知道它们相互作用发生的概率，却无法准确获得中子与原子核作用时的位置以及裂变产生的新中子的行进速率和方向。科学家依据其概率进行随机抽样得到裂变位置、速度和方向，这样模拟大量中子的行为后，经过统计就能获得中子传输的范围，作为反应堆设计的依据。</p>
<p>另一种类型是所求解问题可以转化为某种随机分布的特征数，比如随机事件出现的概率，或者随机变量的期望值。通过随机抽样的方法，以随机事件出现的频率估计其概率，或者以抽样的数字特征估算随机变量的数字特征，并将其作为问题的解。这种方法多用于求解复杂的多维积分问题。</p>
<p>例如，下图阐释了如何利用蒙特卡洛方法来估算 <span class="math inline">\(\pi\)</span> 的值：</p>
<p><img src="https://zhaochenyang20.github.io/gif/pi.gif" style="zoom:70%;" /></p>
<h2 id="前景">前景</h2>
<p>就单纯的用蒙特卡洛方法来下棋（最早在1993年被提出，后在2001被再次提出），我们可以简单的用随机比赛的方式来评价某一步落子。从需要评价的那一步开始，双方随机落子，直到一局比赛结束。为了保证结果的准确性，这样的随机对局通常需要进行上万盘，记录下每一盘的结果，最后取这些结果的平均，就能得到某一步棋的评价。最后要做的就是取评价最高的一步落子作为接下来的落子。也就是说为了决定一步落子就需要程序自己进行上万局的随机对局，这对随机对局的速度也提出了一定的要求。和使用了大量围棋知识的传统方法相比，这种方法的好处显而易见，就是几乎不需要围棋的专业知识，只需通过大量的随机对局就能估计出一步棋的价值。再加上一些优化方法，基于纯蒙特卡洛方法的围棋程序已经能够匹敌最强的传统围棋程序。</p>
<p>既然蒙特卡洛的路似乎充满着光明，我们就应该沿着这条路继续前行。MCTS也就是将以上想法融入到树搜索中，利用树结构来更加高效的进行节点值的更新和选择。</p>
<h1 id="蒙特卡洛树搜索mcts">蒙特卡洛树搜索（MCTS）</h1>
<h2 id="简介-1">简介</h2>
<p>蒙特卡洛树搜索（Monte Carlo tree search；MCTS）是一种用于某些决策过程的启发式搜索算法，最引人注目的是在游戏中的使用。一个主要例子是电脑围棋程序，它也用于其他棋盘游戏、即时电子游戏以及不确定性游戏。</p>
<h2 id="搜索步骤">搜索步骤</h2>
<p><img src="https://zhaochenyang20.github.io/pic/lecture/2022_spring/IAI/MCTS.jpg" alt="MCTS" style="zoom:50%;" /></p>
<ul>
<li>选择(selection)：根据当前获得所有子步骤的统计结果，选择一个最优的子步骤。从根结点R开始，选择连续的子结点向下至叶子结点L。一般而言，让游戏树向最优的方向扩展，这是蒙特卡洛树搜索的精要所在。</li>
<li>扩展(expansion)：在当前获得的统计结果不足以计算出下一个步骤时，随机选择一个子步骤。除非任意一方的输赢使得游戏在 L 结束，否则创建一个或多个子结点并选取其中一个结点 C。</li>
<li>模拟(simulation)：模拟游戏，进入下一步。在从结点C开始，用随机策略进行游戏，又称为playout或者rollout。</li>
<li>反向传播(Back-Propagation)：根据游戏结束的结果，计算对应路径上统计记录的值。使用随机游戏的结果，更新从C到R的路径上的结点信息。</li>
<li>决策（decision）：当到了一定的迭代次数或者时间之后结束，选择根节点下最好的子节点作为本次决策的结果。</li>
</ul>
<p><img src="https://zhaochenyang20.github.io/pic/lecture/2022_spring/IAI/MCTS2.jpg" alt="MCTS" style="zoom:50%;" /></p>
<h2 id="具体算法">具体算法</h2>
<p>在开始阶段，搜索树只有一个节点，也就是我们需要决策的局面。</p>
<p>搜索树中的每一个节点包含了三个基本信息：代表的局面，被访问的次数，累计评分。</p>
<h3 id="选择">选择</h3>
<p>在选择阶段，需要从根节点，也就是要做决策的局面 R 出发向下选择出一个最急迫需要被拓展的节点 N，局面 R 是每一次迭代中第一个被检查的节点；</p>
<p>对于被检查的局面而言，他可能有三种可能：</p>
<ol type="1">
<li>该节点所有可行动作（即所有子节点）都已经被拓展过</li>
<li>该节点有可行动作（还有子节点）还未被拓展过</li>
<li>这个节点游戏已经结束了(例如已经连成四子的四子棋局面)</li>
</ol>
<p>对于这三种可能：</p>
<ol type="1">
<li>如果所有可行动作都已经被拓展过，即所有子节点都有了战绩，那么我们将使用 UCB 公式计算该节点所有子节点的 UCB 值，并找到值最大的一个子节点继续向下迭代。</li>
<li>如果被检查的节点 A 依然存在没有被拓展的子节点 B (也即还有战绩为 0/0 的节点)，那么我们认为 A 节点就是本次迭代的的目标节点，紧接着对 A 进行扩展。</li>
<li>如果被检查到的节点是一个游戏已经结束的节点。那么从该节点直接记录战绩，并且反向传播。</li>
</ol>
<h3 id="扩展">扩展</h3>
<p>在选择阶段结束时候，我们查找到了一个最迫切被拓展的节点 N，以及他一个尚未拓展的动作 A。在搜索树中创建一个新的节点 <span class="math inline">\(N_A\)</span> 作为N的一个新子节点，<span class="math inline">\(N_A\)</span> 的局面就是节点 N 在执行了动作 A 之后的局面。</p>
<h3 id="模拟">模拟</h3>
<p>为了让 <span class="math inline">\(N_A\)</span> 得到一个初始的评分,我们从 <span class="math inline">\(N_A\)</span> 开始，让游戏随机进行，直到得到一个游戏结局，这个结局将作为 <span class="math inline">\(N_A\)</span> 的初始战绩，采用 <span class="math inline">\(\frac{胜场}{总次数}\)</span>来记录。</p>
<h3 id="反向传播">反向传播</h3>
<p>在 <span class="math inline">\(N_A\)</span> 的模拟结束之后，它的父节点 n 以及从根节点到 N 的路径上的所有节点都会根据本次模拟的结果来添加自己的累计评分，注意评分具有交替性。如果在选择阶段直接造成了游戏结局，则跳过模拟，根据该结局来更新评分。</p>
<h3 id="决策">决策</h3>
<p>每一次迭代都会拓展搜索树，随着迭代次数的增加，搜索树的规模也不断增加。当到了一定的迭代次数或者时间之后结束，选择根节点下最好的子节点作为本次决策的结果。</p>
<p><img src="https://zhaochenyang20.github.io/pic/lecture/2022_spring/IAI/MCTS3.jpg" alt="MCTS" style="zoom:50%;" /></p>
<p><img src="https://zhaochenyang20.github.io/pic/lecture/2022_spring/IAI/MCTS4.jpg" alt="MCTS" style="zoom:37%;" /></p>
<h1 id="uct">UCT</h1>
<h2 id="ucb1">UCB1</h2>
<p><span class="math display">\[
UCB1 = V_i + c\sqrt{\frac{\ln{N}}{n_i}}
\]</span></p>
<ul>
<li><span class="math inline">\(V_i\)</span> 表示当前节点 i 的战绩。</li>
<li><span class="math inline">\(N\)</span> 为当前节点的父节点被访问的次数。</li>
<li><span class="math inline">\(n_i\)</span> 为当前节点i被访问的次数。</li>
<li>c 为探索参数，在实际中通常可凭经验选择。c 越大，就会越照顾访问次数相对较少的子节点。</li>
</ul>
<h2 id="mcts-ucb1">MCTS + UCB1</h2>
<p>UCT 算法（Upper Confidence Bound Apply to Tree）即上限置信区间算法，是一种博弈树搜索算法，该算法将蒙特卡洛树搜索方法与UCB公式结合，在超大规模博弈树的搜索过程中相对于传统的搜索算法有着时间和空间方面的优势。</p>
<p>即：MCTS + UCB1 = UCT</p>
<p>算法中的 UCB 公式可替换为：UCB1-tuned 等</p>
<p>UCT 提供了比传统树搜索更好的方法。</p>
<h3 id="优点">优点</h3>
<ul>
<li><p>Aheuristic 启发式</p>
<p>MCTS 不要求任何关于给定的领域策略或者具体实践知识来做出合理的决策。这个算法可以在没有任何关于博弈游戏除基本规则外的知识的情况下进行有效工作；这意味着一个简单的MCTS 实现可以重用在很多的博弈游戏中，只需要进行微小的调整，所以这也使得 MCTS 是对于一般的博弈游戏的很好的方法。</p></li>
<li><p>Asymmetric 非对称</p>
<p>MCTS 执行一种非对称的树的适应搜索空间拓扑结构的增长。这个算法会更频繁地访问更加有趣的节点，并聚焦其搜索时间在更加相关的树的部分。这使得 MCTS 更加适合那些有着更大的分支因子的博弈游戏，比如说 19X19 的围棋。这么大的组合空间会给标准的基于深度或者宽度的搜索方法带来问题，所以MCTS 的适应性说明它（最终）可以找到那些更加优化的行动，并将搜索的工作聚焦在这些部分。</p></li>
<li><p>任何时间</p>
<p>算法可以在任何时间终止，并返回当前最有的估计。当前构造出来的搜索树可以被丢弃或者供后续重用。（对比dfs暴力搜索）</p></li>
<li><p>简洁</p>
<p>算法实现非常方便（ http://mcts.ai/code/python.html ）</p></li>
</ul>
<h3 id="缺点">缺点</h3>
<p>UCT 有缺点很少，但这些缺点也可能是非常关键的影响因素。</p>
<ul>
<li><p>行为能力</p>
<p>UCT 算法，根据其基本形式，在某些甚至不是很大的博弈游戏中在可承受的时间内也不能够找到最好的行动方式。这基本上是由于组合步的空间的全部大小所致，关键节点并不能够访问足够多的次数来给出合理的估计。</p></li>
<li><p>速度</p>
<p>UCT 搜索可能需要足够多的迭代才能收敛到一个很好的解上，这也是更加一般的难以优化的应用上的问题。例如，最佳的围棋程序可能需要百万次的交战和领域最佳和强化才能得到专家级的行动方案，而最有的GGP 实现对更加复杂的博弈游戏可能也就只要每秒钟数十次（领域无关的）交战。对可承受的行动时间，这样的 GGP 可能很少有时间访问到每个合理的行动，所以这样的情形也不大可能出现表现非常好的搜索。</p></li>
</ul>
<h1 id="具体实现">具体实现</h1>
<ul>
<li>为了简洁优雅地实现我的 MCTS 策略，我使用 <code>enhencement.h</code> 来实现了 <code>Node</code> 类和 <code>UCT</code> 类</li>
<li><code>Node</code> 类接口如下：</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span></span></span><br><span class="line"><span class="class">  <span class="title">double</span> <span class="title">profit</span>;</span>                  <span class="comment">// 当前节点的胜率</span></span><br><span class="line">  <span class="keyword">int</span> visit;                        <span class="comment">// 总访问次数</span></span><br><span class="line">  <span class="keyword">int</span> ban_x, ban_y;            <span class="comment">// 被去除的点位</span></span><br><span class="line">  <span class="keyword">int</span> height;                      <span class="comment">// 棋盘高度</span></span><br><span class="line">  <span class="keyword">int</span> width;                       <span class="comment">// 棋盘宽度</span></span><br><span class="line">  <span class="keyword">int</span> expandableNodeNum;            <span class="comment">// 可扩展节点数</span></span><br><span class="line">  <span class="keyword">int</span> position_x, position_y;  <span class="comment">// 落子位置</span></span><br><span class="line">  <span class="keyword">bool</span> expanded;                 <span class="comment">// 是否已经扩展</span></span><br><span class="line">  <span class="keyword">bool</span> chance;                  <span class="comment">// 是否为己方棋子</span></span><br><span class="line">  <span class="keyword">int</span>** boardStatus;  <span class="comment">// 当前局面状况</span></span><br><span class="line">  <span class="keyword">int</span>* topStatus;     <span class="comment">// 当前每一列顶部状况</span></span><br><span class="line">  Node* parent;  <span class="comment">// 父节点</span></span><br><span class="line">  Node** children;     <span class="comment">// 子节点</span></span><br><span class="line">	expand; <span class="comment">// 扩展，用于 treePolicy 中调用</span></span><br><span class="line">	Node <span class="comment">// 构造函数</span></span><br><span class="line">  ~Node <span class="comment">// 析构函数</span></span><br><span class="line">  <span class="keyword">int</span>* expandableNodeID;  <span class="comment">// 从当前节点开始可扩展节点的行号</span></span><br><span class="line"> 	<span class="function"><span class="keyword">int</span> <span class="title">connection</span><span class="params">(chance)</span>	<span class="comment">// 判定需要紧急处理的棋局情况，例如三子共线</span></span></span><br><span class="line"><span class="function">  bestChild</span>; <span class="comment">// 在所有子节点中选择 UCB1 值最高的节点</span></span><br></pre></td></tr></table></figure>
<ul>
<li><code>UCT</code> 类接口如下：</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UCT</span></span></span><br><span class="line"><span class="class">  <span class="title">width</span>, <span class="title">height</span>;</span>  <span class="comment">// 棋盘规格</span></span><br><span class="line">  ban_x, ban_y;   <span class="comment">// 被去除的点位</span></span><br><span class="line">  expanded;      <span class="comment">// 是否已经展开</span></span><br><span class="line">  Node* root;		<span class="comment">// 根节点</span></span><br><span class="line">	UCT <span class="comment">// 构造函数</span></span><br><span class="line">  ~UCT <span class="comment">// 析构函数</span></span><br><span class="line">  search <span class="comment">// 在时间限制内不断运行伪代码，之后给出根节点的最佳子节点</span></span><br><span class="line">  treePolicy <span class="comment">// 即伪代码中的 treePolicy，不再赘述</span></span><br><span class="line">  defaultPolicy <span class="comment">// 即伪代码中的 defaultPolicy，不再赘述</span></span><br></pre></td></tr></table></figure>
<h1 id="相关讨论">相关讨论</h1>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Eren Zhao</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://example.com/2022/05/24/Lecture/2022%20Spring/Reinforcement/">http://example.com/2022/05/24/Lecture/2022%20Spring/Reinforcement/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%A7%91%E7%A0%94/">科研</a><a class="post-meta__tags" href="/tags/2022%E6%98%A5%E5%AD%A3/">2022春季</a></div><div class="post_share"><div class="social-share" data-image="https://pic.imgdb.cn/item/62270f075baa1a80ab393529.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/05/25/%E9%9A%8F%E7%AC%94/%E6%B8%85%E5%8D%8E%E5%9B%AD%E6%97%A5%E8%AE%B0/%E6%B8%85%E5%8D%8E%E5%9B%AD%E6%97%A5%E8%AE%B0--%E7%AC%AC%E4%BA%94%E9%83%A8/"><img class="prev-cover" src="https://pic.imgdb.cn/item/62270f075baa1a80ab393529.jpg" onerror="onerror=null;src='https://wkphoto.cdn.bcebos.com/1f178a82b9014a9058a735deb9773912b31bee3c.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">清华园日记——第五部</div></div></a></div><div class="next-post pull-right"><a href="/2022/05/17/Lecture/2022%20Spring/binaryDivdence/"><img class="next-cover" src="https://pic.imgdb.cn/item/61f106842ab3f51d917b1e67.jpg" onerror="onerror=null;src='https://wkphoto.cdn.bcebos.com/1f178a82b9014a9058a735deb9773912b31bee3c.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">Segement Me If U Can</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2022/05/17/Lecture/2022%20Spring/binaryDivdence/" title="Segement Me If U Can"><img class="cover" src="https://pic.imgdb.cn/item/61f106842ab3f51d917b1e67.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-17</div><div class="title">Segement Me If U Can</div></div></a></div><div><a href="/2022/05/06/%E7%A3%95%E7%9B%90/Enhancing%20photorealism%20enhancement/" title="Enhancing photorealism enhancement"><img class="cover" src="https://pic.imgdb.cn/item/61f0fc802ab3f51d91731ef4.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-06</div><div class="title">Enhancing photorealism enhancement</div></div></a></div><div><a href="/2022/03/15/Lecture/2022%20Spring/Introduction_to_AI/" title="Introduction to Artificial Intelligence"><img class="cover" src="https://pic.imgdb.cn/item/61eccc682ab3f51d91d712d5.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-15</div><div class="title">Introduction to Artificial Intelligence</div></div></a></div><div><a href="/2022/03/23/Lecture/2022%20Spring/Input%20method/" title="How Do We Train An Input Method"><img class="cover" src="https://pic.imgdb.cn/item/61eccb622ab3f51d91d62895.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-23</div><div class="title">How Do We Train An Input Method</div></div></a></div><div><a href="/2022/03/08/%E7%A3%95%E7%9B%90/Fully%20Convolutional%20Networks%20for%20Semantic%20Segmentation/" title="Fully Convolutional Networks for Semantic Segmentation 阅读笔记"><img class="cover" src="https://pic.imgdb.cn/item/61ed14422ab3f51d911d44db.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-08</div><div class="title">Fully Convolutional Networks for Semantic Segmentation 阅读笔记</div></div></a></div><div><a href="/2022/01/10/%E7%A3%95%E7%9B%90/VIT/" title="Vision Transformer Learning Log"><img class="cover" src="https://pic.imgdb.cn/item/61eccc6f2ab3f51d91d71a65.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-01-10</div><div class="title">Vision Transformer Learning Log</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpeg" onerror="this.onerror=null;this.src='/img/friend.jpg'" alt="avatar"/></div><div class="author-info__name">Eren Zhao</div><div class="author-info__description">求道之人，不论寒暑，无问西东</div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">172</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">53</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">12</div></a></div></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/zhaochenyang20"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">La vida sola viviras</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%87%8D%E5%8A%9B%E5%9B%9B%E5%AD%90%E6%A3%8B"><span class="toc-number">1.</span> <span class="toc-text">重力四子棋</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0"><span class="toc-number">2.</span> <span class="toc-text">强化学习</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A6%82%E5%BF%B5"><span class="toc-number">2.1.</span> <span class="toc-text">概念</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%84%E4%BB%B6"><span class="toc-number">2.2.</span> <span class="toc-text">强化学习的基本组件</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8Bmdp"><span class="toc-number">3.</span> <span class="toc-text">马尔可夫决策过程（MDP）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E8%BF%87%E7%A8%8B"><span class="toc-number">3.1.</span> <span class="toc-text">马尔可夫过程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%A5%96%E5%8A%B1%E8%BF%87%E7%A8%8B"><span class="toc-number">3.2.</span> <span class="toc-text">马尔可夫奖励过程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#rl-%E4%B8%8E-mdp"><span class="toc-number">3.3.</span> <span class="toc-text">RL 与 MDP</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%96%B9%E6%B3%95mcm"><span class="toc-number">4.</span> <span class="toc-text">蒙特卡洛方法（MCM）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B"><span class="toc-number">4.1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E6%99%AF"><span class="toc-number">4.2.</span> <span class="toc-text">前景</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%A0%91%E6%90%9C%E7%B4%A2mcts"><span class="toc-number">5.</span> <span class="toc-text">蒙特卡洛树搜索（MCTS）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B-1"><span class="toc-number">5.1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%90%9C%E7%B4%A2%E6%AD%A5%E9%AA%A4"><span class="toc-number">5.2.</span> <span class="toc-text">搜索步骤</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B7%E4%BD%93%E7%AE%97%E6%B3%95"><span class="toc-number">5.3.</span> <span class="toc-text">具体算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%89%E6%8B%A9"><span class="toc-number">5.3.1.</span> <span class="toc-text">选择</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%89%A9%E5%B1%95"><span class="toc-number">5.3.2.</span> <span class="toc-text">扩展</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E6%8B%9F"><span class="toc-number">5.3.3.</span> <span class="toc-text">模拟</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD"><span class="toc-number">5.3.4.</span> <span class="toc-text">反向传播</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%B3%E7%AD%96"><span class="toc-number">5.3.5.</span> <span class="toc-text">决策</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#uct"><span class="toc-number">6.</span> <span class="toc-text">UCT</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#ucb1"><span class="toc-number">6.1.</span> <span class="toc-text">UCB1</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mcts-ucb1"><span class="toc-number">6.2.</span> <span class="toc-text">MCTS + UCB1</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%98%E7%82%B9"><span class="toc-number">6.2.1.</span> <span class="toc-text">优点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%BA%E7%82%B9"><span class="toc-number">6.2.2.</span> <span class="toc-text">缺点</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%B7%E4%BD%93%E5%AE%9E%E7%8E%B0"><span class="toc-number">7.</span> <span class="toc-text">具体实现</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E8%AE%A8%E8%AE%BA"><span class="toc-number">8.</span> <span class="toc-text">相关讨论</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/05/25/%E9%9A%8F%E7%AC%94/%E6%B8%85%E5%8D%8E%E5%9B%AD%E6%97%A5%E8%AE%B0/%E6%B8%85%E5%8D%8E%E5%9B%AD%E6%97%A5%E8%AE%B0--%E7%AC%AC%E4%BA%94%E9%83%A8/" title="清华园日记——第五部"><img src="https://pic.imgdb.cn/item/62270f075baa1a80ab393529.jpg" onerror="this.onerror=null;this.src='https://wkphoto.cdn.bcebos.com/1f178a82b9014a9058a735deb9773912b31bee3c.jpg'" alt="清华园日记——第五部"/></a><div class="content"><a class="title" href="/2022/05/25/%E9%9A%8F%E7%AC%94/%E6%B8%85%E5%8D%8E%E5%9B%AD%E6%97%A5%E8%AE%B0/%E6%B8%85%E5%8D%8E%E5%9B%AD%E6%97%A5%E8%AE%B0--%E7%AC%AC%E4%BA%94%E9%83%A8/" title="清华园日记——第五部">清华园日记——第五部</a><time datetime="2022-05-24T23:05:19.199Z" title="Created 2022-05-25 07:05:19">2022-05-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/05/24/Lecture/2022%20Spring/Reinforcement/" title="connect 4 based on Reinforced Learning"><img src="https://pic.imgdb.cn/item/62270f075baa1a80ab393529.jpg" onerror="this.onerror=null;this.src='https://wkphoto.cdn.bcebos.com/1f178a82b9014a9058a735deb9773912b31bee3c.jpg'" alt="connect 4 based on Reinforced Learning"/></a><div class="content"><a class="title" href="/2022/05/24/Lecture/2022%20Spring/Reinforcement/" title="connect 4 based on Reinforced Learning">connect 4 based on Reinforced Learning</a><time datetime="2022-05-24T06:16:40.717Z" title="Created 2022-05-24 14:16:40">2022-05-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/05/17/Lecture/2022%20Spring/binaryDivdence/" title="Segement Me If U Can"><img src="https://pic.imgdb.cn/item/61f106842ab3f51d917b1e67.jpg" onerror="this.onerror=null;this.src='https://wkphoto.cdn.bcebos.com/1f178a82b9014a9058a735deb9773912b31bee3c.jpg'" alt="Segement Me If U Can"/></a><div class="content"><a class="title" href="/2022/05/17/Lecture/2022%20Spring/binaryDivdence/" title="Segement Me If U Can">Segement Me If U Can</a><time datetime="2022-05-17T07:14:54.399Z" title="Created 2022-05-17 15:14:54">2022-05-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/05/15/%E9%9A%8F%E7%AC%94/%E5%BF%83%E5%BF%83%E5%BF%B5%E5%BF%B5/nonsense/" title="time passed and shall never look back"><img src="https://pic.imgdb.cn/item/62270f5c5baa1a80ab3a4417.jpg" onerror="this.onerror=null;this.src='https://wkphoto.cdn.bcebos.com/1f178a82b9014a9058a735deb9773912b31bee3c.jpg'" alt="time passed and shall never look back"/></a><div class="content"><a class="title" href="/2022/05/15/%E9%9A%8F%E7%AC%94/%E5%BF%83%E5%BF%83%E5%BF%B5%E5%BF%B5/nonsense/" title="time passed and shall never look back">time passed and shall never look back</a><time datetime="2022-05-15T11:22:51.543Z" title="Created 2022-05-15 19:22:51">2022-05-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/05/07/%E9%9A%8F%E7%AC%94/%E5%8D%9A%E6%96%87/%E7%BE%8E%E5%9B%BD%E9%A1%B6%E5%B0%96%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%BA%90%E8%B7%9F%E6%B8%85%E5%8C%97%E5%A4%8D%E4%BA%A4%E6%AF%94%E6%80%8E%E4%B9%88%E6%A0%B7/" title="中国顶尖大学新生比康奈尔新生优秀，但4年后被康奈尔毕业生超越"><img src="https://pic.imgdb.cn/item/61eccb272ab3f51d91d5f874.jpg" onerror="this.onerror=null;this.src='https://wkphoto.cdn.bcebos.com/1f178a82b9014a9058a735deb9773912b31bee3c.jpg'" alt="中国顶尖大学新生比康奈尔新生优秀，但4年后被康奈尔毕业生超越"/></a><div class="content"><a class="title" href="/2022/05/07/%E9%9A%8F%E7%AC%94/%E5%8D%9A%E6%96%87/%E7%BE%8E%E5%9B%BD%E9%A1%B6%E5%B0%96%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%BA%90%E8%B7%9F%E6%B8%85%E5%8C%97%E5%A4%8D%E4%BA%A4%E6%AF%94%E6%80%8E%E4%B9%88%E6%A0%B7/" title="中国顶尖大学新生比康奈尔新生优秀，但4年后被康奈尔毕业生超越">中国顶尖大学新生比康奈尔新生优秀，但4年后被康奈尔毕业生超越</a><time datetime="2022-05-07T14:17:15.505Z" title="Created 2022-05-07 22:17:15">2022-05-07</time></div></div></div></div></div></div></main><footer id="footer" style="background: ＃191970"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By Eren Zhao</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Local search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading the Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/tororo.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/"});</script></body></html>